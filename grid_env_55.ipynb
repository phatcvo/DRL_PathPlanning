{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning) # ignore FutureWarning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transition Probability Table\n",
    "* $\n",
    "P(s'|s,a)\n",
    "$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GridEnv():\n",
    "    def __init__(self):\n",
    "        # Some initialization for Env\n",
    "        self.world_shape = [5,5]\n",
    "        self.world = np.zeros(self.world_shape)\n",
    "        self.agent_pos = [0, 0]\n",
    "        self.obstacle_pos = [[2,2],[2,3]]\n",
    "        self.goal_pos = [4,4]\n",
    "        self.action_space = [0, 1, 2, 3]\n",
    "        \n",
    "        # obsercation space\n",
    "        self.obs_space = self.make_observation_space()\n",
    "        # obstacle space\n",
    "        self.obstacle_space = self.make_obstacle_space()\n",
    "        # transition table\n",
    "        self.trans_table = self.make_transition_table()\n",
    "        \n",
    "    def make_observation_space(self):\n",
    "        obs_space = dict()\n",
    "        for col in range(5):\n",
    "            for row in range(5):\n",
    "                obs_space[row + col*5] = [row,col]\n",
    "        \n",
    "        return obs_space\n",
    "        \n",
    "    def make_obstacle_space(self):\n",
    "        obstacle_space = []\n",
    "        for pos in self.obstacle_pos:\n",
    "            obstacle_space.append(pos[0] + pos[1]*self.world_shape[1])\n",
    "        \n",
    "        return obstacle_space\n",
    "        \n",
    "    def make_transition_table(self):\n",
    "        '''\n",
    "        Transition probability table for Model-based approach\n",
    "        '''\n",
    "        trans_table = np.zeros([len(self.obs_space), len(self.action_space), 3], dtype=int) # (s, a, [s', reward, prob])\n",
    "        \n",
    "        for s in self.obs_space.keys():\n",
    "            for a in self.action_space:\n",
    "                if a == 0:\n",
    "                    x_nxt = self.obs_space[s][0]\n",
    "                    y_nxt = self.obs_space[s][1] + 1\n",
    "                    s_nxt = s + 5\n",
    "                elif a == 1:\n",
    "                    x_nxt = self.obs_space[s][0]\n",
    "                    y_nxt = self.obs_space[s][1] - 1\n",
    "                    s_nxt = s - 5\n",
    "                elif a == 2:\n",
    "                    x_nxt = self.obs_space[s][0] - 1\n",
    "                    y_nxt = self.obs_space[s][1]\n",
    "                    s_nxt = s - 1\n",
    "                else:\n",
    "                    x_nxt = self.obs_space[s][0] + 1\n",
    "                    y_nxt = self.obs_space[s][1]\n",
    "                    s_nxt = s + 1\n",
    "\n",
    "                if x_nxt == 4 and y_nxt == 4:\n",
    "                    trans_table[s][a] = [s_nxt, 200, 1] # goal position\n",
    "                elif x_nxt < 0 or x_nxt > 4 or y_nxt < 0 or y_nxt > 4:\n",
    "                    trans_table[s][a] = [s, -50 ,1] # out of world\n",
    "                elif [x_nxt, y_nxt] in self.obstacle_pos:\n",
    "                    trans_table[s][a] = [s, -50, 1] # obstacle position\n",
    "                else:\n",
    "                    trans_table[s][a] = [s_nxt, -1, 1] # free space\n",
    "        \n",
    "        return trans_table\n",
    "    \n",
    "    def transition(self, s, a):\n",
    "        return self.trans_table[s][a]\n",
    "    \n",
    "    # action step\n",
    "    def step(self, action):\n",
    "        if action == 0: #up\n",
    "            self.agent_pos[1] += 1\n",
    "        elif action == 1: # down\n",
    "            self.agent_pos[1] -= 1\n",
    "        elif action == 2: # left\n",
    "            self.agent_pos[0] -= 1\n",
    "        elif action == 3: # right\n",
    "            self.agent_pos[0] += 1\n",
    "        else:\n",
    "            raise Exception(\"the action is not defined\")\n",
    "\n",
    "        info = {}\n",
    "\n",
    "        return (self._get_reward(), self._get_obs(), self._is_done(), info)\n",
    "    \n",
    "    # 환경을 초기화\n",
    "    def reset(self):\n",
    "        self.world = np.zeros(self.world_shape)\n",
    "        self.agent_pos = [0, 0]\n",
    "        \n",
    "        return self._get_obs()\n",
    "\n",
    "    # 환경의 현재 상태 시각화\n",
    "    def render(self):\n",
    "        # visualize grid map\n",
    "        fig = plt.figure(figsize=(3, 3))\n",
    "        for i in range(self.world_shape[0]): # row\n",
    "            for j in range(self.world_shape[1]): # col      \n",
    "                plt.gcf().gca().add_patch(patches.Rectangle((i,j), 1, 1, edgecolor = 'black', fill=False))\n",
    "\n",
    "        # agent position\n",
    "        plt.gcf().gca().add_patch(patches.Rectangle((self.agent_pos[0], self.agent_pos[1]),\n",
    "                                                    1, 1, edgecolor = 'black', facecolor = 'yellow', fill=True))\n",
    "        # goal position\n",
    "        plt.gcf().gca().add_patch(patches.Rectangle((self.goal_pos[0], self.goal_pos[1]),\n",
    "                                                    1, 1, edgecolor = 'black', facecolor = 'red', fill=True))        \n",
    "        # obstacle position\n",
    "        for pos in self.obstacle_pos:\n",
    "            plt.gcf().gca().add_patch(patches.Rectangle((pos[0],pos[1]),\n",
    "                                                        1, 1, edgecolor = 'black', facecolor = 'grey', fill=True))\n",
    "\n",
    "        plt.plot()\n",
    "        plt.show()\n",
    "\n",
    "#     def close(self):\n",
    "#         pass\n",
    "\n",
    "    def _back_to_field(self):\n",
    "        # out of the map, back to previous state\n",
    "        if self.agent_pos[0] < 0:\n",
    "            self.agent_pos[0] = 0\n",
    "        elif self.agent_pos[0] > 4:\n",
    "            self.agent_pos[0] = 4\n",
    "        elif self.agent_pos[1] < 0:\n",
    "            self.agent_pos[1] = 0\n",
    "        elif self.agent_pos[1] > 4:\n",
    "            self.agent_pos[1] = 4\n",
    "\n",
    "            \n",
    "    def _get_reward(self):\n",
    "        if self.agent_pos == self.goal_pos:\n",
    "            return 200\n",
    "        elif self.agent_pos in self.obstacle_pos:\n",
    "            return -50\n",
    "        # out of the map, back to previous state\n",
    "        elif self.agent_pos[0] < 0 or self.agent_pos[0] > 4 or self.agent_pos[1] < 0 or self.agent_pos[1] > 4:\n",
    "            return -50\n",
    "        else:\n",
    "            return -1\n",
    "        \n",
    "    # Get observation\n",
    "    def _get_obs(self):\n",
    "        # out of the map, back to previous state\n",
    "        if self.agent_pos[0] < 0 or self.agent_pos[0] > 4 or self.agent_pos[1] < 0 or self.agent_pos[1] > 4:\n",
    "            self._back_to_field()\n",
    "        return self.agent_pos[0] + self.agent_pos[1]*self.world_shape[1]\n",
    "\n",
    "\n",
    "    \n",
    "    def _is_done(self):\n",
    "        # out of the map, back to previous state\n",
    "#         if self.agent_pos[0] < 0 or self.agent_pos[0] > 4 or self.agent_pos[1] < 0 or self.agent_pos[1] > 4:\n",
    "# #             self._back_to_field()\n",
    "#             return True\n",
    "        # agent located at obstacle point\n",
    "        if self.agent_pos in self.obstacle_pos:\n",
    "            return False\n",
    "        # agent located at goal point\n",
    "        elif self.agent_pos == self.goal_pos:\n",
    "            return True\n",
    "        else:\n",
    "            return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Policy Visualization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def policy_visualize(env, policy, title=\"given policy\"):\n",
    "    fig = plt.figure(figsize=(4,4))\n",
    "    plt.title(title)\n",
    "    \n",
    "    for i in range(env.world_shape[0]): # row\n",
    "        for j in range(env.world_shape[1]): # col      \n",
    "            plt.gcf().gca().add_patch(patches.Rectangle((i,j), 1, 1, edgecolor = 'black', fill=False))\n",
    "            \n",
    "            # start state\n",
    "            if i == 0 and j == 0:\n",
    "                plt.gcf().gca().add_patch(patches.Rectangle((i,j), 1, 1, edgecolor = 'black', facecolor = 'yellow', fill=True))        \n",
    "            \n",
    "            # obstacle state\n",
    "            if [i,j] in env.obstacle_pos:\n",
    "                plt.gcf().gca().add_patch(patches.Rectangle((i,j), 1, 1, edgecolor = 'black', facecolor = 'grey', fill=True))\n",
    "            \n",
    "            # terminal state\n",
    "            if i == 4 and j == 4:\n",
    "                plt.gcf().gca().add_patch(patches.Rectangle((i,j), 1, 1, edgecolor = 'black', facecolor = 'red', fill=True))\n",
    "                continue\n",
    "            \n",
    "            '''\n",
    "            action visualization\n",
    "            '''\n",
    "            # up\n",
    "            plt.gcf().gca().add_patch(patches.Arrow(i+0.5, j+0.5, 0, 0.5, width = 0.2,\n",
    "                                                    alpha = policy[i + j*env.world_shape[1]][0],\n",
    "                                                    facecolor = 'green', fill=True))\n",
    "            # down\n",
    "            plt.gcf().gca().add_patch(patches.Arrow(i+0.5, j+0.5, 0, -0.5, width = 0.2,\n",
    "                                                    alpha = policy[i + j*env.world_shape[1]][1],\n",
    "                                                    facecolor = 'green', fill=True))\n",
    "            # left\n",
    "            plt.gcf().gca().add_patch(patches.Arrow(i+0.5, j+0.5, -0.5, 0, width = 0.2,\n",
    "                                                    alpha = policy[i + j*env.world_shape[1]][2],\n",
    "                                                    facecolor = 'green',fill=True))\n",
    "            # right\n",
    "            plt.gcf().gca().add_patch(patches.Arrow(i+0.5, j+0.5, 0.5, 0, width = 0.2,\n",
    "                                                    alpha = policy[i + j*env.world_shape[1]][3],\n",
    "                                                    facecolor = 'green',fill=True))\n",
    "\n",
    "    plt.plot()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### State Value Function $V(s)$ Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def StateValueFunction_visualize(env, V, title='State Value Function'):\n",
    "    fig = plt.figure(figsize=(4,4))\n",
    "    plt.title(title)\n",
    "    plt.imshow(V, cmap='copper', interpolation='none')\n",
    "    plt.colorbar()\n",
    "\n",
    "    for i in range(5):\n",
    "        for j in range(5):\n",
    "            plt.text(j,i,round(V[i][j],1), color='white', fontsize='small', ha='center',va='center')\n",
    "\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Action Value Function $Q(s,a)$ Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ActionValueFunction_visualize(env, Q, title='Action Value Function'):\n",
    "    fig = plt.figure(figsize=(4,4))\n",
    "    plt.title(title)\n",
    "    \n",
    "    n_state, n_action = Q.shape\n",
    "    \n",
    "    # action visulization\n",
    "    lft_tri = np.array([[0,0],[-0.5,-0.5],[-0.5,0.5]])\n",
    "    up_tri = np.array([[0,0],[-0.5,0.5],[0.5,0.5]])\n",
    "    dw_tri = np.array([[0,0],[0.5,-0.5],[-0.5,-0.5]])\n",
    "    rgh_tri = np.array([[0,0],[0.5,0.5],[0.5,-0.5]])\n",
    "    \n",
    "    # Color\n",
    "    high_color = np.array([0.0, 1.0, 0.0, 0.8])\n",
    "    low_color  = np.array([1.0, 1.0, 1.0, 0.8])\n",
    "    \n",
    "    text_fs = 6\n",
    "    \n",
    "    for i in range(env.world_shape[0]): # row\n",
    "        for j in range(env.world_shape[1]): # col\n",
    "            \n",
    "            # start state\n",
    "            if i == 0 and j == 0:\n",
    "                plt.gcf().gca().add_patch(patches.Rectangle((i-0.5,j-0.5), 1, 1, edgecolor = 'black', facecolor = 'yellow', fill=True))        \n",
    "            \n",
    "            # obstacle state\n",
    "            if [i,j] in env.obstacle_pos:\n",
    "                plt.gcf().gca().add_patch(patches.Rectangle((i-0.5,j-0.5), 1, 1, edgecolor = 'black', facecolor = 'grey', fill=True))\n",
    "            \n",
    "            # terminal state\n",
    "            if i == 4 and j == 4:\n",
    "                plt.gcf().gca().add_patch(patches.Rectangle((i-0.5,j-0.5), 1, 1, edgecolor = 'black', facecolor = 'red', fill=True))            \n",
    "            \n",
    "            s = j*env.world_shape[1]+i\n",
    "            min_q = np.min(Q[s])\n",
    "            max_q = np.max(Q[s])\n",
    "            for a in range(n_action):\n",
    "                q_value = Q[s,a]\n",
    "                ratio = (q_value - min_q)/(max_q - min_q + 1e-10) \n",
    "                \n",
    "                if ratio > 1:\n",
    "                    clr = high_color\n",
    "                elif ratio < 0:\n",
    "                    clr = low_color\n",
    "                else:\n",
    "                    clr = high_color*ratio + low_color*(1-ratio)\n",
    "                \n",
    "                if a == 0: # up\n",
    "                    plt.gca().add_patch(plt.Polygon([i,j]+up_tri, color=clr, ec='k'))\n",
    "                    plt.text(i+0.0, j+0.25,\"%.2f\"%(q_value),fontsize=text_fs,va='center', ha='center')\n",
    "                if a == 1: # down\n",
    "                    plt.gca().add_patch(plt.Polygon([i,j]+dw_tri, color=clr, ec='k'))\n",
    "                    plt.text(i+0.0, j-0.25,\"%.2f\"%(q_value),fontsize=text_fs,va='center', ha='center')\n",
    "                if a == 2: # left\n",
    "                    plt.gca().add_patch(plt.Polygon([i,j]+lft_tri, color=clr, ec='k'))\n",
    "                    plt.text(i-0.25, j+0.0,\"%.2f\"%(q_value),fontsize=text_fs,va='center', ha='center')\n",
    "                if a == 3: # right\n",
    "                    plt.gca().add_patch(plt.Polygon([i,j]+rgh_tri, color=clr, ec='k'))\n",
    "                    plt.text(i+0.25, j+0.0,\"%.2f\"%(q_value),fontsize=text_fs,va='center', ha='center')\n",
    "\n",
    "    plt.xlim([-0.5,env.world_shape[1]-0.5])\n",
    "    plt.xticks(range(env.world_shape[1]))\n",
    "    plt.ylim([-0.5,env.world_shape[1]-0.5])\n",
    "    plt.yticks(range(env.world_shape[1]))\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
